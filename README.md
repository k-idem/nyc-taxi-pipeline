# NYCâ€¯Taxi âœˆ â€“ Miniâ€¯ELT Warehouse  
GCS â–¸ BigQuery â–¸ dbt â–¸ Kestra

![Architecture diagram](images/architecture.png)

A fullyâ€‘containerised pipeline that lands raw Parquet taxiâ€‘trip files in **Googleâ€¯Cloudâ€¯Storage**, stages them in **BigQuery**, transforms them with **dbt** and lets you browse lineage & docs on **localhost:8088**.  
`docker compose up -d` â†’â€¯done in â‰ˆ2â€¯min.

---

## Tableâ€¯ofâ€¯contents
1. [Architecture](#-architecture)
2. [Prerequisites](#-prerequisites)
3. [Folder layout](#-folder-layout)
4. [Quickâ€‘start](#-quickâ€‘start)
5. [Stepâ€‘byâ€‘step](#-stepâ€‘byâ€‘step)
6. [Troubleshooting](#-troubleshooting)

---

## Architecture
![Lineage](images/dbt_lineage.png)

| Layer | Service | How it runs |
|-------|---------|-------------|
| **Orchestrator** | Kestra (`server standalone`) | Docker container â€“â€¯<http://localhost:8080> |
| **Metadata** | Postgres | container, keeps Kestra metadata |
| **Landing zone** | GCS bucket (`dtc-data-lakeâ€‘zoomcamp-deâ€‘463203`) | public Parquet data |
| **Warehouse** | BigQuery<br>`trips_data_all`Â (raw) â†’ `zoomcamp_de`Â (models) | one SA, two datasets |
| **Transform** | dbtÂ CoreÂ 1.8 |â€¯CLI container |
| **Docs** | dbtÂ DocsÂ (Flask) | served on **localhost:8088** |

---

## ğŸ›  Prerequisites
| What |Â Why |Â NotesÂ |
|------|-----|-------|
| **Docker** &Â **Dockerâ€¯ComposeÂ v2** | run everything | `docker --version` |
| **gcloudâ€¯SDK** | optional, create BQ dataset | `gcloud components install` |
| `gcp_key.json` | SA key with **BigQueryâ€¯Editor** + **Storageâ€¯Objectâ€¯Viewer** | put in repo root |

> **Serviceâ€‘account roles**  
> *ProjectÂ `zoomcampâ€‘deâ€‘463203`*: `roles/bigquery.dataEditor` & `roles/storage.objectViewer`  
> *ProjectÂ `taxiâ€‘ridesâ€‘nyâ€‘339813`*: `roles/bigquery.dataViewer`

---

## FolderÂ layout
nyc-taxi-pipeline/
â”œâ”€ docker-compose.yml # all services
â”œâ”€ flows/ # Kestra YAML flows
â”œâ”€ dbt/ # dbt project (taxi_rides_ny)
â”‚ â”œâ”€ models/â€¦
â”‚ â””â”€ profiles.yml
â”œâ”€ images/ # screenshots & architecture
â”œâ”€ gcp_key.json # â† your SA key here
â””â”€ README.md

### Screenshots & diagrams

| Preview | Purpose |
|---------|---------|
| ![Architecture](images/architecture.png) | **Endâ€‘toâ€‘end architecture** â€“ highâ€‘level flow |
| ![Lineage](images/dbt_lineage.png) | **dbtÂ lineage graph** (localhost:8088) |
| ![dbtÂ run](images/dbt_run.png) | **dbtÂ run + test output** â€“ terminal snapshot |
| ![BigQuery tables](images/bq_table.png) | **BigQuery dataset view** â€“ resulting tables |
| ![KestraÂ DAG](images/kestra_DAG_view.png) | **Kestra flow DAG** â€“ task dependencies |
| ![KestraÂ Gantt](images/kestra_gantt_view.png) | **Kestra Gantt chart** â€“ task durations |


---

## Quickâ€‘start

```bash
# 1. clone and cd
git clone https://github.com/k-idem/nyc-taxi-pipeline.git
cd nyc-taxi-pipeline

# 2. add your serviceâ€‘account key
cp ~/Downloads/my-key.json ./gcp_key.json

# 3. spin everything
docker compose up -d

# 4. open Kestra (optional)
open http://localhost:8080        # or xdg-open / start

# 5. trigger the flow in UI OR run dbt locally
docker compose run --rm dbt deps
docker compose run --rm dbt seed
docker compose run --rm dbt run && \
docker compose run --rm dbt test
docker compose run --rm -p 8088:8080 dbt docs serve

# 6. browse docs & lineage
open http://localhost:8088
